After the initial preprocessing was done, additional data handling was performed as required for each model. The environment settings and parameters were then configured, followed by the execution of the experimental procedure and a statistical analysis of the results. The following segments detail the specifications of the experimental environment and provide a comprehensive description of the experimental scenarios that were conducted.

\begin{figure}[h]
    \centering
    \scalebox{0.4}{\input{imgs/tikz/experiments}}
    \caption{Experiments flow.}
    \label{fig:experiments_flow}
\end{figure}

% Commented as requested by the teacher
% \subsubsection{Environment}

The server used for running the experiments was composed of 2 Intel(R) Xeon(R) Gold 6240 CPU @ 2.60GHz, 2 NVIDIA Tesla V100S PCIE-32GB, 256Gb RAM, and 3TB storage. The server runned Clear Linux and used Slurm, a workload manager that allows users to schedule jobs and manage clusters of nodes. It also had access to a variety of software applications, including CUDA and Miniconda. For these experiments, a conda environment was set with pytorch.

% Commented as requested by the teacher
% \subsubsection{Scenarios}

Each replicate, or run, consisted of a training session followed by a testing session. In the training sessions, the dataset was randomly divided into a training subset and a validation subset, adhering to the proportions specified for each model. The model was then trained on the training subset for its designated number of epochs, optimizing its ability to classify ICT. In the testing session, the model's classification performance was evaluated using the validation subset, with all relevant metrics recorded. The experiment comprised a total of 10 replicates for model.

As previously mentioned, ViVit was trained using entire image sequences as input, aligning with its design as a video model capable of processing sequential data. In contrast, ConvNeXT was trained on individual images, as its structure as an image-based model does not support sequence-based training. This approach results in a larger training dataset for ConvNeXT compared to ViVit, which may had introduced bias. However, this strategy was maintained to ensure an objective comparison of their performance on this dataset and avoid introducing further experimental noise by manipulating data differently for each model.

% Commented to make it more concise
% In testing, ViVit's performance was evaluated based on its ability to classify entire image sequences. ConvNeXT, however, required a slightly different approach: it received an entire image sequence but classified each image individually. A sequence was then classified as positive if at least one image within it was classified as positive; otherwise, it was classified as negative. This approach was chosen to minimize false negatives, which are particularly concerning in medical applications.